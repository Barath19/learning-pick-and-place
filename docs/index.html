<html lang="en-US">
  <head>
    <meta charset="UTF-8">

    <title>Learning Pick-and-place</title>
    <meta property="og:title" content="Self-supervised Learning for Precise Pick-and-place without Object Model">
    <meta property="og:locale" content="en_US">
    <meta name="description" content="Self-supervised Learning for Precise Pick-and-place without Object Model">
    <meta property="og:description" content="Self-supervised Learning for Precise Pick-and-place without Object Model">
    <link rel="canonical" href="https://pantor.github.io/learning-pick-and-place/">
    <meta property="og:url" content="https://pantor.github.io/learning-pick-and-place/">
    <meta property="og:site_name" content="learning-pick-and-place">
    <script type="application/ld+json">
      {"headline":"Self-supervised Learning for Precise Pick-and-place without Object Model","@type":"WebSite","url":"https://pantor.github.io/learning-pick-and-place/","name":"learning-pick-and-place","description":"Self-supervised Learning for Precise Pick-and-place without Object Model","@context":"http://schema.org"
    }
    </script>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="style.css">
  </head>

  <body>
    <div class="main-content" style="display: flex; justify-content: space-between; flex-wrap: wrap;">
      <img src="assets/logos/logo-kit.png" height="82em" />
      <img src="assets/logos/logo-ipr.png" height="82em" />
    </div>

    <header class="page-header" role="banner">
      <h1 class="project-name">Self-supervised Learning for Precise Pick-and-place without&nbsp;Object Model</h1>
      <h2 class="project-tagline">
        Lars&nbsp;Berscheid, Pascal&nbsp;Meißner, and Torsten&nbsp;Kröger<br>
        <a href="https://ipr.kit.edu" style="color: white;">Intelligent&nbsp;Process&nbsp;Automation and Robotics&nbsp;Lab&nbsp;(IPR), Karlsruhe&nbsp;Institute of&nbsp;Technology&nbsp;(KIT)</a>
      </h2>

      <!--a href="https://drive.google.com/file/d/1JDOeTVgLxhnPdZ3bylB2vNiiSRr2-69p/view?usp=sharing" class="btn" disabled>View Paper (Draft)</a-->
      <a href="https://drive.google.com/open?id=1hzcznKXEXthOF4fyJpVBqbDcyCdueb_q" class="btn">View Video</a>
      <a href="https://github.com/pantor/learning-pick-and-place" class="btn">View Code</a>
    </header>

    <main id="content" class="main-content" role="main">
      <center>
        <h3>Abstract</h3>
        <p class="text">
		Flexible pick-and-place is a fundamental yet challenging task within robotics, in particular due to the need of an object model for a simple target pose definition.
		In this work, the robot instead learns to pick-and-place objects using planar manipulation according to a single, demonstrated goal state.
		Our primary contribution lies within combining robot learning of primitives, commonly estimated by fully-convolutional neural networks, with one-shot imitation learning.
		Therefore, we define the place reward as a contrastive loss between real-world measurements and a task-specific noise distribution.
		Furthermore, we design our system to learn in a self-supervised manner, enabling real-world experiments with up to 25000 pick-and-place actions.
		Then, our robot is able to place trained objects with an average placement error of 2.7±0.2 mm and 2.6±0.8°.
		As our approach does not require an object model, the robot is able to generalize to unknown objects keeping a precision of 5.9±1.1 mm and 4.1±1.2°.
		We further show a range of emerging behaviors:
		The robot naturally learns to select the correct object in the presence of multiple object types, precisely inserts objects within a peg game, picks screws out of dense clutter, and infers multiple pick-and-place actions from a single goal state.
	</p>
  
        <h3>Conference Video</h3>
        <div class="videobereich">
          <iframe class="videoextern" src="https://drive.google.com/file/d/1hzcznKXEXthOF4fyJpVBqbDcyCdueb_q/preview" width="640" height="480" frameborder="0" allowfullscreen></iframe>
        </div>
      </center>
	    
      <hr style="margin: 5em; margin-top: 6em;">

      <h2>Supplementary Material</h2>
      <p class="text">
      	Below, we show supplementary videos of our pick-and-place system.
				As our approach places objects according to a demonstrated goal state, it does not require an object model.
				We've trained two models:
				First, a model using RGBD-images handling screws on around 3500 pick-and-place actions.
				Second, a general model using depth-images trained while manipulating wooden objects with around 25000 pick-and-place actions.
				It is used for all further experiments without screws.
      </p>
			
			
			<h3>Unknown Objects</h3>
			<p class="text">
      	As no object model is needed, our system is able to pick-and-place even unknown objects with high precision.
      </p>
			
			<div class="videobereich">
          <iframe class="videoextern" src="https://drive.google.com/file/d/13fKhRBFfDtJIuZS7PZE0a7_HMfS5NLtJ/preview" width="640" height="480" frameborder="0" allowfullscreen></iframe>
      </div>
      <div class="video-caption"><b>Video 1</b> Pick-and-place of various unknown objects.</div>
			
			
			<h3>Insertion Task</h3>
			<p class="text">
      	To further demonstrate the precision of our system, we evaluate insertion tasks with small tolerances.
				The robot achieves success rates - depending on the object type - of up to 90% despite grasping out of clutter.
      </p>
			
			<div class="videobereich">
          <iframe class="videoextern" src="https://drive.google.com/file/d/15EtIIgF82n8fP1sRrL3InbSW8NqTY-u-/preview" width="640" height="480" frameborder="0" allowfullscreen></iframe>
      </div>
      <div class="video-caption"><b>Video 2</b> Playing the peg game.</div>
			
			<div class="videobereich">
          <iframe class="videoextern" src="https://drive.google.com/file/d/1sPvapKrkFMof6r4FXFbXIrALU1dVvgDm/preview" width="640" height="480" frameborder="0" allowfullscreen></iframe>
      </div>
      <div class="video-caption"><b>Video 3</b> Inserting a screw into a custom-designed holder.</div>
			
	    
      <h3>Multiple Actions</h3>
			<p class="text">
      	Our robot is able to infer multiple pick-and-place actions from a single goal state.
      </p>
			
      <div class="videobereich">
          <iframe class="videoextern" src="https://drive.google.com/file/d/16NdOv_DnqTnZuyejMnWwtg-25bPpuqwT/preview" width="640" height="480" frameborder="0" allowfullscreen></iframe>
      </div>
      <div class="video-caption"><b>Video 4</b> Placing the logo of our Alma Mater, the Karlsruhe Institute of Technology (KIT).</div>
	    
      <div class="videobereich">
          <iframe class="videoextern" src="https://drive.google.com/file/d/1NmNa5tPUC3LgOdAAsjVDiCLKcLF1vzBI/preview" width="640" height="480" frameborder="0" allowfullscreen></iframe>
      </div>
			<div class="video-caption"><b>Video 5</b> Precisely isolating multiple screws out of dense clutter.</div>
			
			<div class="videobereich">
          <iframe class="videoextern" src="https://drive.google.com/file/d/1J9JiC4P_aav5dQFfeh0fC_RXDTTS5t4r/preview" width="640" height="480" frameborder="0" allowfullscreen></iframe>
      </div>
			<div class="video-caption"><b>Video 6</b> Demonstrating the flexibility of our one-shot imitation learning approach. For some examples, we demonstrate multiple goal states as an instruction list.</div>

			
      <footer class="site-footer">
        <span class="site-footer-credits">
          To explore our work even further:
          <ul>
            <li><a href="https://techxplore.com/news/2019-08-algorithm-robots-pre-grasping-strategies.html">A TechXplore article about pre-grasping manipulation</a></li>
            <li><a href="https://en.ids-imaging.com/casestudies-detail/en_seen-stored-learned.html">An IDS article about our work from an industrial perspective</a></li>
            <li><a href="https://ipr.kit.edu">Our research group at IPR / KIT.</a></li>
          </ul>
        </span>
      </footer>
    </main>

    <footer class="page-header" role="banner">
      <span class="site-footer-owner">Lars Berscheid</span>

      <p>
        Intelligent Process Automation and Robotics Lab (IPR)<br>
        Karlsruhe Institute of Technology (KIT)<br>
        &copy; 2020
      </p>
    </footer>
    
    <!-- Templates -->
    <script type="text/x-template" id="steps-carousel-template">
      <div>
        <div style="display: flex; align-items: center; flex-wrap: nowrap; overflow-y: scroll;">
          <div v-for="i in steps.length" ref="steps" style="min-width: 300px; margin: 5px;">
            <p>
              <b>Step {{ i - 1 }}</b> <small v-if="i - 1 == 0">(Image Measurement)</small><br>
              Reward: {{ steps[i - 1].reward }}<br>
              Estimation: {{ steps[i - 1].estimated_reward }} <span v-if="steps[i - 1].estimated_reward_std">± {{ steps[i - 1].estimated_reward_std }}</span><br>
              Action:
              <span v-if="steps[i - 1].action_type < 3">Grasp (Type {{ steps[i - 1].action_type }})</span>
              <span v-if="steps[i - 1].action_type == 3">Shift</span>
              <span v-if="steps[i - 1].action_type == 4">Bin Empty</span>
            </p>
  
            <div v-bind:class="current_step == i-1 ? 'highlight-image' : ''">
              <img :src="`assets/${name}/result-${i - 1}.jpg`" v-on:click="setStep(i - 1, steps.length)"/>
              <img :src="`assets/${name}/uncertainty-${i - 1}.jpg`" v-on:click="setStep(i - 1, steps.length)"/>
            </div>
          </div>
        </div>
  
        <div style="display: flex; justify-content: space-between">
          <div>
            <button class="button-left chevron left" v-on:click="setStep(current_step - 1, steps.length)" :disabled="current_step <= 0"></button>
          </div>
        
          <div>
            <button class="button-right chevron right" v-on:click="setStep(current_step + 1, steps.length)" :disabled="current_step >= steps.length - 1"></button>
          </div>
        </div>
      </div>
    </script>

    <script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
		
    <script src="script.js"></script>
  </body>
</html>
